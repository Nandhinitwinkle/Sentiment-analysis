{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of sentiment_analysis_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8_qpIQMYIBR",
        "outputId": "af81020c-3e11-41ca-be02-02e555f7f4e6"
      },
      "source": [
        "pip install tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.32.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.1)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow) (54.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (0.4.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.27.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOuxEynmYRjL",
        "outputId": "56212542-ede0-4c08-a17d-9ce11b577663"
      },
      "source": [
        "pip install keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.4.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZSE5114YUDf"
      },
      "source": [
        "import pandas as pd \r\n",
        "import numpy as np\r\n",
        "import re\r\n",
        "import collections\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "# Packages for data preparation\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.utils.np_utils import to_categorical\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "\r\n",
        "# Packages for modeling\r\n",
        "from keras import models\r\n",
        "from keras import layers\r\n",
        "from keras import regularizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTVvbH0mB268"
      },
      "source": [
        "NB_WORDS = 10000  # Parameter indicating the number of words we'll put in the dictionary\r\n",
        "VAL_SIZE = 1000  # Size of the validation set\r\n",
        "NB_START_EPOCHS = 20  # Number of epochs we usually start to train with\r\n",
        "BATCH_SIZE = 512  # Size of the batches used in the mini-batch gradient descent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "td6kJyik8fTB",
        "outputId": "2ddea23b-af70-4873-b7be-a3ca41d9aab0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "qv5gyfAaYUFw",
        "outputId": "1b6446ee-a39b-4510-c7a5-06688f66de82"
      },
      "source": [
        "a = pd.read_csv(\"finaldata.csv\", engine='python')\r\n",
        "a.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviews</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\\t\\t\\t\\t\\t\\t\\tSamsung you love\\t\\t\\t\\t\\t\\t\\t\\t...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\t\\t\\t\\t\\t\\t\\tMeanwhile apple introducing dark...</td>\n",
              "      <td>neautral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\t\\t\\t\\t\\t\\t\\tA fantastic pohne u\\t\\t\\t\\t\\t\\t\\...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\t\\t\\t\\t\\t\\t\\tHow much in Bangladesh?\\t\\t\\t\\t\\...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\t\\t\\t\\t\\t\\t\\tHow much GB storage does it have...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Reviews     label\n",
              "0  \\t\\t\\t\\t\\t\\t\\tSamsung you love\\t\\t\\t\\t\\t\\t\\t\\t...  positive\n",
              "1  \\t\\t\\t\\t\\t\\t\\tMeanwhile apple introducing dark...  neautral\n",
              "2  \\t\\t\\t\\t\\t\\t\\tA fantastic pohne u\\t\\t\\t\\t\\t\\t\\...  positive\n",
              "3  \\t\\t\\t\\t\\t\\t\\tHow much in Bangladesh?\\t\\t\\t\\t\\...  positive\n",
              "4  \\t\\t\\t\\t\\t\\t\\tHow much GB storage does it have...  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "Qn2uVvbLYUIL",
        "outputId": "0fdfe7e9-77e0-4461-af2b-3d6cf262f0f4"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "#from nltk.corpus import stopwords\r\n",
        "#stopwords.words('english')\r\n",
        "def remove_stopwords(input_text):\r\n",
        "  stopwords_list = stopwords.words('english')\r\n",
        "  whitelist = [\"n't\", \"not\", \"no\"]\r\n",
        "  words = input_text.split() \r\n",
        "  clean_words = [word for word in words if (word not in stopwords_list or word in whitelist) and len(word) > 1] \r\n",
        "  return \" \".join(clean_words) \r\n",
        "    \r\n",
        "def remove_mentions(input_text):\r\n",
        "  return re.sub(r'@\\w+', '', input_text)\r\n",
        "       \r\n",
        "a.Reviews = a.Reviews.apply(remove_stopwords).apply(remove_mentions)\r\n",
        "a.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviews</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Samsung love</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Meanwhile apple introducing darkmode iPhones????</td>\n",
              "      <td>neautral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fantastic pohne</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How much Bangladesh?</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How much GB storage have?</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Reviews     label\n",
              "0                                      Samsung love  positive\n",
              "1  Meanwhile apple introducing darkmode iPhones????  neautral\n",
              "2                                   fantastic pohne  positive\n",
              "3                              How much Bangladesh?  positive\n",
              "4                         How much GB storage have?  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZNf3XNfFcyv",
        "outputId": "603bc887-8135-4b11-d5c2-35360d752162"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(a.Reviews, a.label, test_size=0.1, random_state=37)\r\n",
        "print('# Train data samples:', x_train.shape[0])\r\n",
        "print('# Test data samples:', x_test.shape[0])\r\n",
        "assert x_train.shape[0] == y_train.shape[0]\r\n",
        "assert x_test.shape[0] == y_test.shape[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Train data samples: 58651\n",
            "# Test data samples: 6517\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kq30JBFWFf1U"
      },
      "source": [
        "tk = Tokenizer(num_words=NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=\" \")\r\n",
        "tk.fit_on_texts(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0y67Txh6Ff3m",
        "outputId": "b04b7c5f-f4a1-4875-d516-3a8c74cdf34f"
      },
      "source": [
        "print('Fitted tokenizer on {} documents'.format(tk.document_count))\r\n",
        "print('{} words in dictionary'.format(tk.num_words))\r\n",
        "print('Top 5 most common words are:', collections.Counter(tk.word_counts).most_common(5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitted tokenizer on 58651 documents\n",
            "10000 words in dictionary\n",
            "Top 5 most common words are: [('samsung', 12356), ('youtube', 10978), ('com', 9176), ('www', 7056), ('channel', 7052)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_pzzR5pFf5x",
        "outputId": "86054227-5b6a-4f39-b805-60a22d18e624"
      },
      "source": [
        "x_train_seq = tk.texts_to_sequences(x_train)\r\n",
        "x_test_seq = tk.texts_to_sequences(x_test) \r\n",
        "print('\"{}\" is converted into {}'.format(x_train[0], x_train_seq[0])) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"Samsung love\" is converted into [214, 118, 79, 1571, 140, 542, 2138]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SB2RiLuUFf8M",
        "outputId": "b71539c9-493a-47e8-c8cd-8a93ed458179"
      },
      "source": [
        "def one_hot_seq(seqs, nb_features = NB_WORDS):\r\n",
        "    ohs = np.zeros((len(seqs), nb_features))\r\n",
        "    for i, s in enumerate(seqs):\r\n",
        "        ohs[i, s] = 1.\r\n",
        "    return ohs\r\n",
        "\r\n",
        "x_train_oh = one_hot_seq(x_train_seq)\r\n",
        "x_test_oh = one_hot_seq(x_test_seq)\r\n",
        "\r\n",
        "print('\"{}\" is converted into {}'.format(x_train_seq[0], x_train_oh[0]))\r\n",
        "print('For this example we have {} features with a value of 1.'.format(x_train_oh[0].sum()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"[214, 118, 79, 1571, 140, 542, 2138]\" is converted into [0. 0. 0. ... 0. 0. 0.]\n",
            "For this example we have 7.0 features with a value of 1.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lucx482MFs_I",
        "outputId": "06310161-cfea-4981-c0bc-a628e0a78826"
      },
      "source": [
        "le = LabelEncoder()\r\n",
        "y_train_le = le.fit_transform(y_train)\r\n",
        "y_test_le = le.transform(y_test)\r\n",
        "y_train_oh = to_categorical(y_train_le)\r\n",
        "y_test_oh = to_categorical(y_test_le)\r\n",
        "\r\n",
        "print('\"{}\" is converted into {}'.format(y_train[0], y_train_le[0]))\r\n",
        "print('\"{}\" is converted into {}'.format(y_train_le[0], y_train_oh[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"positive\" is converted into 0\n",
            "\"0\" is converted into [1. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbxJ_yMTFyLx",
        "outputId": "f023ddbb-549b-4ff3-b3be-067804d365fc"
      },
      "source": [
        "print(x_train_oh)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFxFzntKd29c",
        "outputId": "f01deca7-9cb7-43ef-9548-86c32d9ffbf0"
      },
      "source": [
        "print(y_train_le)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 2 ... 1 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4YMM_1ueFQJ",
        "outputId": "b5361ba7-559c-4391-842f-750db4cca3d7"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\r\n",
        "classifier.fit(x_train_oh, y_train_le)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=0, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7-5d0_z2E_i"
      },
      "source": [
        "y_pred_dr = classifier.predict(x_test_oh)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdymS2S32Nk_",
        "outputId": "c71e3b21-1990-41e8-c278-d6460086213b"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\r\n",
        "cm = confusion_matrix(y_test_le, y_pred_dr)\r\n",
        "print(cm)\r\n",
        "accuracy_score(y_test_le, y_pred_dr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3621   27   69]\n",
            " [  45  790   92]\n",
            " [  93   87 1693]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9366272824919442"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHdStO6z2etI"
      },
      "source": [
        "from sklearn.svm import SVC\r\n",
        "svc_ml = SVC(kernel = 'linear', random_state = 0)\r\n",
        "svc_ml.fit(x_train_oh, y_train_le)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtGoDUnKpYT8",
        "outputId": "078f659d-b610-425f-920f-2abcb9964faf"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "knn_ml = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\r\n",
        "knn_ml.fit(x_train_oh, y_train_le)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KxI6kEysY5I"
      },
      "source": [
        "y_pred_knn = knn_ml.predict(x_test_oh)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-Z26vxkst7h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aec5ea56-94d2-4c1f-b10f-dd399f6b51dc"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\r\n",
        "cm = confusion_matrix(y_test_le, y_pred_knn)\r\n",
        "print(cm)\r\n",
        "accuracy_score(y_test_le, y_pred_knn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3702    3   12]\n",
            " [ 354  535   38]\n",
            " [ 723  100 1050]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8112628510050637"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9VUrKvgeeAw"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "rfcc = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 0)\r\n",
        "rfcc.fit(x_train_oh, y_train_le)\r\n",
        "y_pred_rfcc = rfcc.predict(x_test_oh)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLoLHbzqf-l_",
        "outputId": "9728b647-076f-4a86-da68-d3e2a9baf208"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\r\n",
        "cm = confusion_matrix(y_test_le, y_pred_rfcc)\r\n",
        "print(cm)\r\n",
        "accuracy_score(y_test_le, y_pred_rfcc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3665   11   41]\n",
            " [ 108  753   66]\n",
            " [ 160  114 1599]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9232775817093755"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    }
  ]
}